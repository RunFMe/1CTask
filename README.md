
# 1CTask
## Какую модель я использовал?
Наша задача - обнаружение мошеннических вакансий. Ее можно сформулировать как задачу классификкации или задачу детекции аномалий. В постановке с детекцией аномалий требуется больше знаний об области и настройки алгоритма, поэтому я выбрал классификацию. В качестве модели я использовал CatboostClassifier, потому что градиентный бустинг почти всегда дает одни из самых лучших результатов для задачи + catboost умеет очень хорошо обрабатывать категориальные признаки, которых в данных очень много.
## Обработка данных

### Численные признаки
Такой признак всего один и это salary_range, его легко развернуть в два поля - максимальная и минимальная зарплата. При конвертации можно найти поля, в которых вместо зарплаты находятся даты, их мы заменяем на nan. Catboost умеет справляться с nan в численных признаках, выделяя их при бакетировании в отдельный бакет и считая минус бесконечностью, так что дальнейшей обработки не требуется.

### Категориальные признаки
Опять же благодаря catboost нам почти ничего не нужно ничего делать, только заменить nan на строчку NaN. Внутри себя catboost произведет target encoding или другую более подходящую кодировку этих фичей.

**Альтернативный вариант обработки**: Мы могли заменять слова на их embedding'и, таким образом получив больше информации о взаимоотношении разных категорий и, возможно, улучшив предсказания.

### Текстовые признаки

Я считаю, что без объединения всех текстовых признаков в один мы получим более шумные фичи, из которых будет труднее извлечь информацию. Обоснование: наша модель все равно не сможет извлечь сложные взаимоотношения между словами и общий смысл текста. Единственное, на что мы можем рассчитывать, это какие-то слова-'red flags', которые и указывают, на плохую вакансию. И нет никакой разницы, в каком именно поле этот красный флаг появляется. 

Текстовые NaN мы заменяем на строчку 'NaN', потому что это позволит узнать, сколько полей было пустыми.

К тексту мы применяем TfIdf, чтобы извлечь признаки и оставляем 100 наиболее важных. Число 100 может попробовать менять, возможно, улучшив результат.

**Альтернативный вариант обработки**: Вместо применения TfIdf мы могли использовать предобученные вектора для слов и взять средний вектор среди всех слов, сделав этот средний вектор нашей новой фичей. Такая модель называется BagOfEmbedings и она является state of the art для быстрой классификации текстов. Почему я выбрал не ее: как я уже говорил, скорее всего в тексте стоит искать именно слова-'red flags', но такие слова могут становиться красными флагами только в контексте объявлений о работе, а в повседневной речи не быть сколько-ниубдь особенными. Это значит, что они бы не так сильно повлияли на среднее, и мы могли получить более плохой результат. Но эту гипотезу стоит проверить.

### Обучение
В конце мы обучаем на полученных фичах catboost, используя в качестве метрики для отбора моделей ROC-AUC, потому что датасет несбалансирован и любая метрика, основанная на неком пороге для отнесения к классу дала бы необъективные результаты (accuracy, recall, precision, f1, etc). 
Перед запуском в Production модель стоит снова переобучить на всех данных, чтобы не терять данные из валидационной части.
Если мы хотим запутсить эту модель в production и нам нужно получать бинарные значения целевой переменной, а не вероятности, то нужно определить некий threshold, основываясь на допустимых precision/recall.
